{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pNHvuXXrzdo"
   },
   "source": [
    "## URL for Blog post: <a href=\"https://vrk6637.wixsite.com/website/post/cifar-10-image-classification\"> Blog </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BG_BoPd_aRF9"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "icy8fa9Iliwx"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import time \n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qnrB1ogBq-o_"
   },
   "outputs": [],
   "source": [
    "train_dur = []\n",
    "accu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnZfiW1rY6MR",
    "outputId": "961e5101-7860-43e8-9563-6d9f96e2ca63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 550,570\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.7856 - accuracy: 0.3582\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.4213 - accuracy: 0.4894\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.2520 - accuracy: 0.5543\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.1251 - accuracy: 0.6042\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.0286 - accuracy: 0.6404\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.9412 - accuracy: 0.6713\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.8726 - accuracy: 0.6967\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.8010 - accuracy: 0.7209\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.7431 - accuracy: 0.7423\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.6876 - accuracy: 0.7628\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.6280 - accuracy: 0.7823\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.5805 - accuracy: 0.7971\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.5301 - accuracy: 0.8160\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.4839 - accuracy: 0.8312\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.4421 - accuracy: 0.8449\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3909 - accuracy: 0.8652\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3529 - accuracy: 0.8767\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3188 - accuracy: 0.8884\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.2730 - accuracy: 0.9037\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.2416 - accuracy: 0.9160\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.2059 - accuracy: 0.9280\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1830 - accuracy: 0.9351\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1452 - accuracy: 0.9495\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1339 - accuracy: 0.9531\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1223 - accuracy: 0.9571\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1075 - accuracy: 0.9618\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0818 - accuracy: 0.9720\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0837 - accuracy: 0.9700\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0773 - accuracy: 0.9737\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0723 - accuracy: 0.9747\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0545 - accuracy: 0.9819\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0580 - accuracy: 0.9797\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0455 - accuracy: 0.9848\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0507 - accuracy: 0.9823\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0329 - accuracy: 0.9896\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0298 - accuracy: 0.9902\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0539 - accuracy: 0.9812\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0351 - accuracy: 0.9886\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0349 - accuracy: 0.9883\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0110 - accuracy: 0.9974\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0051 - accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 8.5569e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 3.8693e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 2.9743e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 2.5424e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 2.2410e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 2.0134e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.8400e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.7015e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.5748e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.4718e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.3826e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.3090e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.2406e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.1788e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.1274e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.0763e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.0321e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 9.9419e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 9.5590e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 9.2060e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 8.9002e-05 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 8.6042e-05 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 8.3398e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 8.0797e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 7.8376e-05 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 7.6216e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 7.3959e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 7.2138e-05 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 7.0202e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 6.8423e-05 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 6.6731e-05 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 6.5204e-05 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 6.3670e-05 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 6.2158e-05 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 6.0838e-05 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 5.9470e-05 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 5.8235e-05 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 5.7042e-05 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 5.5889e-05 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 5.4751e-05 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 5.3771e-05 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 5.2716e-05 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 5.1738e-05 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 5.0816e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 4.9860e-05 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 4.9058e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 4.8206e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 4.7366e-05 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 4.6624e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 4.5839e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 4.5135e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 4.4405e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 4.3715e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 4.3060e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 4.2424e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 4.1803e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 4.1208e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 4.0622e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 4.0044e-05 - accuracy: 1.0000\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 2.8446 - accuracy: 0.7279\n",
      "<keras.engine.sequential.Sequential at 0x7f34345bcd10>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "def prep_pixels(train, test):\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "def modelone():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "\tprint(model.summary())\n",
    "    \n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "    \n",
    "\tstart = time.time()\n",
    "\tmodel.fit(trainX, trainY, epochs=100, batch_size=64, verbose=1)\n",
    "\tend = time.time()\n",
    "    \n",
    "\ttrain_dur.append(end - start)\n",
    "    \n",
    "\tmodel.save(\"modelone.h5\")\n",
    "\tfiles.download(\"modelone.h5\")\n",
    "\tacc = model.evaluate(testX, testY)\n",
    "    \n",
    "\taccu.append(acc[1])\n",
    "\treturn model\n",
    "\n",
    "    \n",
    "    \n",
    "\treturn model\n",
    "\n",
    "def modeltwo():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "\tprint(model.summary())\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "    \n",
    "\tstart = time.time()\n",
    "\tmodel.fit(trainX, trainY, epochs=100, batch_size=64, verbose=1)\n",
    "\tend = time.time()\n",
    "    \n",
    "\ttrain_dur.append(end - start)\n",
    "\tmodel.save(\"modeltwo.h5\")\n",
    "\tfiles.download(\"modeltwo.h5\")\n",
    "\tacc = model.evaluate(testX, testY)\n",
    "    \n",
    "\taccu.append(acc[1])\n",
    "\treturn model\n",
    "\n",
    "def modelthree():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\tprint(model.summary())\n",
    "    \n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\tstart = time.time()\n",
    "\tmodel.fit(trainX, trainY, epochs=200, batch_size=64, verbose=1)\n",
    "\tend = time.time()\n",
    "    \n",
    "\ttrain_dur.append(end - start)\n",
    "    \n",
    "\tmodel.save(\"modelthree.h5\")\n",
    "\tfiles.download(\"modelthree.h5\")\n",
    "\tacc = model.evaluate(testX, testY)\n",
    "\taccu.append(acc[1])\n",
    "\n",
    "\treturn model\n",
    "\n",
    "modelone()\n",
    "# modeltwo()\n",
    "# modelthree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raKHBXy5pw0E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4099
    },
    "id": "DWmW3eKBCM9Y",
    "outputId": "d89aada0-c894-4d99-a781-5141f3af8cea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 578,250\n",
      "Trainable params: 578,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 20s 24ms/step - loss: 1.8452 - accuracy: 0.3234\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.5173 - accuracy: 0.4449\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 1.3783 - accuracy: 0.5005\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 1.2881 - accuracy: 0.5363\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 1.2008 - accuracy: 0.5703\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 1.1316 - accuracy: 0.5963\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 1.0606 - accuracy: 0.6237\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 1.0089 - accuracy: 0.6415\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.9631 - accuracy: 0.6575\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.9245 - accuracy: 0.6738\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.8875 - accuracy: 0.6859\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.8565 - accuracy: 0.6965\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.8255 - accuracy: 0.7104\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.8018 - accuracy: 0.7169\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.7749 - accuracy: 0.7246\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.7562 - accuracy: 0.7350\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.7288 - accuracy: 0.7406\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.7102 - accuracy: 0.7483\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.6900 - accuracy: 0.7551\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.6743 - accuracy: 0.7602\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.6532 - accuracy: 0.7686\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.6431 - accuracy: 0.7726\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.6276 - accuracy: 0.7782\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.6121 - accuracy: 0.7845\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5986 - accuracy: 0.7882\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.5852 - accuracy: 0.7920\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5747 - accuracy: 0.7954\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5644 - accuracy: 0.7993\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5478 - accuracy: 0.8063\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5374 - accuracy: 0.8086\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5309 - accuracy: 0.8119\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5160 - accuracy: 0.8179\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5079 - accuracy: 0.8190\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4970 - accuracy: 0.8259\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4882 - accuracy: 0.8251\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4800 - accuracy: 0.8305\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4664 - accuracy: 0.8342\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4624 - accuracy: 0.8356\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4574 - accuracy: 0.8373\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4469 - accuracy: 0.8417\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4315 - accuracy: 0.8482\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.4261 - accuracy: 0.8465\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4213 - accuracy: 0.8495\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.4152 - accuracy: 0.8536\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.4072 - accuracy: 0.8548\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.3969 - accuracy: 0.8579\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3899 - accuracy: 0.8608\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3801 - accuracy: 0.8648\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3753 - accuracy: 0.8654\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3709 - accuracy: 0.8662\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3576 - accuracy: 0.8714\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3567 - accuracy: 0.8713\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3498 - accuracy: 0.8735\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3475 - accuracy: 0.8755\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3355 - accuracy: 0.8802\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3303 - accuracy: 0.8813\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3245 - accuracy: 0.8826\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.3244 - accuracy: 0.8839\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.3140 - accuracy: 0.8858\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.3128 - accuracy: 0.8882\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.3005 - accuracy: 0.8915\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.3002 - accuracy: 0.8899\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2930 - accuracy: 0.8939\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2899 - accuracy: 0.8957\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2822 - accuracy: 0.8970\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2759 - accuracy: 0.8999\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2764 - accuracy: 0.8999\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2696 - accuracy: 0.9017\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2608 - accuracy: 0.9060\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2593 - accuracy: 0.9057\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2536 - accuracy: 0.9065\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2471 - accuracy: 0.9096\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2422 - accuracy: 0.9121\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2386 - accuracy: 0.9131\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2335 - accuracy: 0.9159\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2294 - accuracy: 0.9157\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2296 - accuracy: 0.9154\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2266 - accuracy: 0.9178\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2174 - accuracy: 0.9207\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 0.2132 - accuracy: 0.9223\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2133 - accuracy: 0.9220\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2025 - accuracy: 0.9275\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2043 - accuracy: 0.9262\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2002 - accuracy: 0.9278\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1974 - accuracy: 0.9274\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1980 - accuracy: 0.9270\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1938 - accuracy: 0.9300\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1904 - accuracy: 0.9303\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1870 - accuracy: 0.9325\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1855 - accuracy: 0.9323\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1806 - accuracy: 0.9355\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1772 - accuracy: 0.9352\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1780 - accuracy: 0.9358\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1718 - accuracy: 0.9380\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1710 - accuracy: 0.9379\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1683 - accuracy: 0.9385\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1674 - accuracy: 0.9393\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1604 - accuracy: 0.9417\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1635 - accuracy: 0.9406\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.1608 - accuracy: 0.9422\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_c1ef395d-2e67-4eaf-ac22-206367a67371\", \"modeltwo.h5\", 4699744)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.5959 - accuracy: 0.7979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f33bbadb890>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeltwo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZVWazCZD074",
    "outputId": "bb753cdd-982b-4f55-ae72-6d50e51c144c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47049999237060547,\n",
       " 0.7279000282287598,\n",
       " 0.7979000210762024,\n",
       " 0.8166000247001648]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PoE1VpJaD04V",
    "outputId": "e5f93345-9eb3-4ffd-9bd6-6ab7a13cb49d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83.56456089019775, 1494.842612028122, 2003.7363409996033, 3323.5528275966644]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0eouDCED00X",
    "outputId": "1e330526-3255-4bcf-ff6e-fb50b34bee31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83.56456089019775, 1494.842612028122, 2003.7363409996033, 3323.5528275966644]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7459
    },
    "id": "bQCOBFJ4TBjR",
    "outputId": "cf1193a4-d628-4796-e715-c6e1444f2fb2"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 550,570\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.7642 - accuracy: 0.3575\n",
      "Epoch 2/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.4428 - accuracy: 0.4764\n",
      "Epoch 3/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.2877 - accuracy: 0.5368\n",
      "Epoch 4/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.1634 - accuracy: 0.5836\n",
      "Epoch 5/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.0783 - accuracy: 0.6160\n",
      "Epoch 6/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.0058 - accuracy: 0.6435\n",
      "Epoch 7/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.9537 - accuracy: 0.6624\n",
      "Epoch 8/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.9016 - accuracy: 0.6816\n",
      "Epoch 9/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.8618 - accuracy: 0.6952\n",
      "Epoch 10/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.8184 - accuracy: 0.7115\n",
      "Epoch 11/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.7831 - accuracy: 0.7232\n",
      "Epoch 12/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.7531 - accuracy: 0.7346\n",
      "Epoch 13/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.7199 - accuracy: 0.7460\n",
      "Epoch 14/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.6921 - accuracy: 0.7568\n",
      "Epoch 15/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.6719 - accuracy: 0.7644\n",
      "Epoch 16/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.6461 - accuracy: 0.7731\n",
      "Epoch 17/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.6278 - accuracy: 0.7767\n",
      "Epoch 18/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.6037 - accuracy: 0.7897\n",
      "Epoch 19/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.5888 - accuracy: 0.7926\n",
      "Epoch 20/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.5762 - accuracy: 0.7983\n",
      "Epoch 21/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.5552 - accuracy: 0.8049\n",
      "Epoch 22/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.5341 - accuracy: 0.8112\n",
      "Epoch 23/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.5213 - accuracy: 0.8163\n",
      "Epoch 24/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.5069 - accuracy: 0.8210\n",
      "Epoch 25/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.4897 - accuracy: 0.8275\n",
      "Epoch 26/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.4731 - accuracy: 0.8327\n",
      "Epoch 27/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.4599 - accuracy: 0.8370\n",
      "Epoch 28/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.4512 - accuracy: 0.8410\n",
      "Epoch 29/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.4316 - accuracy: 0.8473\n",
      "Epoch 30/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.4228 - accuracy: 0.8493\n",
      "Epoch 31/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.4055 - accuracy: 0.8551\n",
      "Epoch 32/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.4001 - accuracy: 0.8571\n",
      "Epoch 33/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3858 - accuracy: 0.8631\n",
      "Epoch 34/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3725 - accuracy: 0.8655\n",
      "Epoch 35/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3685 - accuracy: 0.8684\n",
      "Epoch 36/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3561 - accuracy: 0.8720\n",
      "Epoch 37/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3468 - accuracy: 0.8758\n",
      "Epoch 38/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3324 - accuracy: 0.8808\n",
      "Epoch 39/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3230 - accuracy: 0.8839\n",
      "Epoch 40/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3134 - accuracy: 0.8859\n",
      "Epoch 41/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.3024 - accuracy: 0.8918\n",
      "Epoch 42/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2931 - accuracy: 0.8936\n",
      "Epoch 43/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2849 - accuracy: 0.8968\n",
      "Epoch 44/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2769 - accuracy: 0.9001\n",
      "Epoch 45/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2711 - accuracy: 0.9010\n",
      "Epoch 46/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2575 - accuracy: 0.9079\n",
      "Epoch 47/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2494 - accuracy: 0.9100\n",
      "Epoch 48/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2483 - accuracy: 0.9102\n",
      "Epoch 49/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2380 - accuracy: 0.9121\n",
      "Epoch 50/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2356 - accuracy: 0.9145\n",
      "Epoch 51/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2235 - accuracy: 0.9183\n",
      "Epoch 52/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2265 - accuracy: 0.9175\n",
      "Epoch 53/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2108 - accuracy: 0.9231\n",
      "Epoch 54/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2069 - accuracy: 0.9248\n",
      "Epoch 55/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2006 - accuracy: 0.9271\n",
      "Epoch 56/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1927 - accuracy: 0.9296\n",
      "Epoch 57/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1872 - accuracy: 0.9316\n",
      "Epoch 58/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1782 - accuracy: 0.9345\n",
      "Epoch 59/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1833 - accuracy: 0.9315\n",
      "Epoch 60/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1737 - accuracy: 0.9366\n",
      "Epoch 61/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1699 - accuracy: 0.9385\n",
      "Epoch 62/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1636 - accuracy: 0.9413\n",
      "Epoch 63/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1631 - accuracy: 0.9418\n",
      "Epoch 64/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1560 - accuracy: 0.9434\n",
      "Epoch 65/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1518 - accuracy: 0.9449\n",
      "Epoch 66/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1443 - accuracy: 0.9469\n",
      "Epoch 67/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1462 - accuracy: 0.9468\n",
      "Epoch 68/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1427 - accuracy: 0.9470\n",
      "Epoch 69/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1357 - accuracy: 0.9514\n",
      "Epoch 70/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1351 - accuracy: 0.9503\n",
      "Epoch 71/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1295 - accuracy: 0.9519\n",
      "Epoch 72/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1282 - accuracy: 0.9547\n",
      "Epoch 73/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1213 - accuracy: 0.9570\n",
      "Epoch 74/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1203 - accuracy: 0.9564\n",
      "Epoch 75/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1208 - accuracy: 0.9567\n",
      "Epoch 76/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1174 - accuracy: 0.9582\n",
      "Epoch 77/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1149 - accuracy: 0.9582\n",
      "Epoch 78/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1135 - accuracy: 0.9582\n",
      "Epoch 79/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1097 - accuracy: 0.9605\n",
      "Epoch 80/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1077 - accuracy: 0.9606\n",
      "Epoch 81/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1067 - accuracy: 0.9608\n",
      "Epoch 82/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1018 - accuracy: 0.9628\n",
      "Epoch 83/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0954 - accuracy: 0.9658\n",
      "Epoch 84/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1018 - accuracy: 0.9644\n",
      "Epoch 85/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0939 - accuracy: 0.9665\n",
      "Epoch 86/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0940 - accuracy: 0.9674\n",
      "Epoch 87/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0950 - accuracy: 0.9660\n",
      "Epoch 88/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0917 - accuracy: 0.9682\n",
      "Epoch 89/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0858 - accuracy: 0.9690\n",
      "Epoch 90/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0838 - accuracy: 0.9699\n",
      "Epoch 91/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0862 - accuracy: 0.9693\n",
      "Epoch 92/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0820 - accuracy: 0.9710\n",
      "Epoch 93/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0838 - accuracy: 0.9698\n",
      "Epoch 94/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0848 - accuracy: 0.9695\n",
      "Epoch 95/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0859 - accuracy: 0.9689\n",
      "Epoch 96/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0775 - accuracy: 0.9723\n",
      "Epoch 97/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0791 - accuracy: 0.9719\n",
      "Epoch 98/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0731 - accuracy: 0.9740\n",
      "Epoch 99/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0728 - accuracy: 0.9736\n",
      "Epoch 100/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0728 - accuracy: 0.9741\n",
      "Epoch 101/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0717 - accuracy: 0.9747\n",
      "Epoch 102/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0709 - accuracy: 0.9749\n",
      "Epoch 103/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0710 - accuracy: 0.9745\n",
      "Epoch 104/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0714 - accuracy: 0.9746\n",
      "Epoch 105/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0694 - accuracy: 0.9750\n",
      "Epoch 106/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0672 - accuracy: 0.9760\n",
      "Epoch 107/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0684 - accuracy: 0.9762\n",
      "Epoch 108/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0667 - accuracy: 0.9765\n",
      "Epoch 109/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0655 - accuracy: 0.9769\n",
      "Epoch 110/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0630 - accuracy: 0.9771\n",
      "Epoch 111/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0630 - accuracy: 0.9771\n",
      "Epoch 112/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0608 - accuracy: 0.9783\n",
      "Epoch 113/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0625 - accuracy: 0.9781\n",
      "Epoch 114/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0623 - accuracy: 0.9782\n",
      "Epoch 115/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0640 - accuracy: 0.9776\n",
      "Epoch 116/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0647 - accuracy: 0.9769\n",
      "Epoch 117/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0561 - accuracy: 0.9805\n",
      "Epoch 118/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0587 - accuracy: 0.9790\n",
      "Epoch 119/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0534 - accuracy: 0.9814\n",
      "Epoch 120/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0562 - accuracy: 0.9796\n",
      "Epoch 121/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0574 - accuracy: 0.9803\n",
      "Epoch 122/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0533 - accuracy: 0.9808\n",
      "Epoch 123/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0539 - accuracy: 0.9808\n",
      "Epoch 124/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0533 - accuracy: 0.9808\n",
      "Epoch 125/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0547 - accuracy: 0.9809\n",
      "Epoch 126/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0521 - accuracy: 0.9818\n",
      "Epoch 127/200\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.0525 - accuracy: 0.9822\n",
      "Epoch 128/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0506 - accuracy: 0.9821\n",
      "Epoch 129/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0535 - accuracy: 0.9817\n",
      "Epoch 130/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0504 - accuracy: 0.9826\n",
      "Epoch 131/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0501 - accuracy: 0.9820\n",
      "Epoch 132/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0489 - accuracy: 0.9827\n",
      "Epoch 133/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0480 - accuracy: 0.9830\n",
      "Epoch 134/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0489 - accuracy: 0.9831\n",
      "Epoch 135/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0463 - accuracy: 0.9835\n",
      "Epoch 136/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0471 - accuracy: 0.9831\n",
      "Epoch 137/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0446 - accuracy: 0.9844\n",
      "Epoch 138/200\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.0462 - accuracy: 0.9834\n",
      "Epoch 139/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0455 - accuracy: 0.9844\n",
      "Epoch 140/200\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.0489 - accuracy: 0.9830\n",
      "Epoch 141/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0446 - accuracy: 0.9841\n",
      "Epoch 142/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0430 - accuracy: 0.9849\n",
      "Epoch 143/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0465 - accuracy: 0.9834\n",
      "Epoch 144/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0460 - accuracy: 0.9845\n",
      "Epoch 145/200\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.0438 - accuracy: 0.9852\n",
      "Epoch 146/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0416 - accuracy: 0.9848\n",
      "Epoch 147/200\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.0428 - accuracy: 0.9851\n",
      "Epoch 148/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0408 - accuracy: 0.9862\n",
      "Epoch 149/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0411 - accuracy: 0.9853\n",
      "Epoch 150/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0407 - accuracy: 0.9856\n",
      "Epoch 151/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0409 - accuracy: 0.9852\n",
      "Epoch 152/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0401 - accuracy: 0.9859\n",
      "Epoch 153/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0424 - accuracy: 0.9856\n",
      "Epoch 154/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0409 - accuracy: 0.9859\n",
      "Epoch 155/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0391 - accuracy: 0.9865\n",
      "Epoch 156/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0431 - accuracy: 0.9851\n",
      "Epoch 157/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0391 - accuracy: 0.9859\n",
      "Epoch 158/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0366 - accuracy: 0.9873\n",
      "Epoch 159/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0387 - accuracy: 0.9871\n",
      "Epoch 160/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0390 - accuracy: 0.9860\n",
      "Epoch 161/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0372 - accuracy: 0.9866\n",
      "Epoch 162/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0348 - accuracy: 0.9881\n",
      "Epoch 163/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0352 - accuracy: 0.9876\n",
      "Epoch 164/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0380 - accuracy: 0.9873\n",
      "Epoch 165/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0349 - accuracy: 0.9878\n",
      "Epoch 166/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0368 - accuracy: 0.9871\n",
      "Epoch 167/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0365 - accuracy: 0.9871\n",
      "Epoch 168/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0346 - accuracy: 0.9877\n",
      "Epoch 169/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0363 - accuracy: 0.9873\n",
      "Epoch 170/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0366 - accuracy: 0.9870\n",
      "Epoch 171/200\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.0349 - accuracy: 0.9876\n",
      "Epoch 172/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0332 - accuracy: 0.9880\n",
      "Epoch 173/200\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.0339 - accuracy: 0.9877\n",
      "Epoch 174/200\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.0355 - accuracy: 0.9872\n",
      "Epoch 175/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0318 - accuracy: 0.9890\n",
      "Epoch 176/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0331 - accuracy: 0.9887\n",
      "Epoch 177/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0343 - accuracy: 0.9880\n",
      "Epoch 178/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0348 - accuracy: 0.9886\n",
      "Epoch 179/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0341 - accuracy: 0.9881\n",
      "Epoch 180/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0312 - accuracy: 0.9893\n",
      "Epoch 181/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0330 - accuracy: 0.9886\n",
      "Epoch 182/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0316 - accuracy: 0.9893\n",
      "Epoch 183/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0308 - accuracy: 0.9892\n",
      "Epoch 184/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0329 - accuracy: 0.9896\n",
      "Epoch 185/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0313 - accuracy: 0.9893\n",
      "Epoch 186/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0287 - accuracy: 0.9900\n",
      "Epoch 187/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0305 - accuracy: 0.9891\n",
      "Epoch 188/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0288 - accuracy: 0.9905\n",
      "Epoch 189/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0308 - accuracy: 0.9894\n",
      "Epoch 190/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0337 - accuracy: 0.9886\n",
      "Epoch 191/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0326 - accuracy: 0.9890\n",
      "Epoch 192/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0324 - accuracy: 0.9893\n",
      "Epoch 193/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0286 - accuracy: 0.9903\n",
      "Epoch 194/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0289 - accuracy: 0.9896\n",
      "Epoch 195/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0300 - accuracy: 0.9896\n",
      "Epoch 196/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0300 - accuracy: 0.9899\n",
      "Epoch 197/200\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0275 - accuracy: 0.9904\n",
      "Epoch 198/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0319 - accuracy: 0.9893\n",
      "Epoch 199/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0315 - accuracy: 0.9897\n",
      "Epoch 200/200\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.0295 - accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_48b4cbd3-03b3-4407-a2bc-2b7ccb35d93d\", \"modelthree.h5\", 4478560)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7244 - accuracy: 0.8166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f33bb406d50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelthree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Or90ux3uf6vb"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwHQDSfEhfTN",
    "outputId": "fbf232b1-f045-405b-aff8-bb9a5a313040"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modelone': 0.7279000282287598,\n",
       " 'modelthree': 0.8166000247001648,\n",
       " 'modeltwo': 0.7979000210762024}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = {}\n",
    "\n",
    "acc[\"modelone\"] = accu[1]\n",
    "acc[\"modeltwo\"] = accu[2]\n",
    "acc[\"modelthree\"] = accu[3]\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "iwjHcXg1i0IT"
   },
   "outputs": [],
   "source": [
    "accy = [i*100 for i in accu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "iacxTJlzhhJB",
    "outputId": "1561e141-18b5-440e-836d-15d3b37d9afd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = sns.barplot(x=[\"modelone\", \"modeltwo\", \"modelthree\"], y=accy[1:])\n",
    "\n",
    "plt.set_xlabel(\"Model\", fontsize = 20)\n",
    "plt.set_ylabel(\"Accuracy\", fontsize = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "WB3EuepuiFnL",
    "outputId": "7d5a2bf1-42ba-432f-be3d-0789cddfb4a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training Duration')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = sns.barplot(x=[\"modelone\", \"modeltwo\", \"modelthree\"], y=train_dur[1:])\n",
    "\n",
    "plt.set_xlabel(\"Model\", fontsize = 20)\n",
    "plt.set_ylabel(\"Training Duration\", fontsize = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwVgVqJjkrD0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of cifar10_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
